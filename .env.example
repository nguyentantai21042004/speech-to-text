# ============================================================================
# SMAP Speech-to-Text - Environment Configuration
# ============================================================================

# ============================================================================
# Application Settings
# ============================================================================
APP_NAME=SMAP Speech-to-Text
APP_VERSION=1.0.0
ENVIRONMENT=development
DEBUG=True

# ============================================================================
# API Service Settings
# ============================================================================
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=True
API_WORKERS=1
MAX_UPLOAD_SIZE_MB=500

# ============================================================================
# Storage Settings
# ============================================================================
# Whisper Library Settings (Dynamic Model Loading)
# ============================================================================
# Model size for direct C library integration
# Options: base (60MB, ~1GB RAM), small (181MB, ~500MB RAM), or medium (1.5GB, ~2GB RAM)
# Change this to switch models without rebuilding Docker image!
WHISPER_MODEL_SIZE=small

# Base directory for Whisper library artifacts
# Models are organized in: {WHISPER_ARTIFACTS_DIR}/whisper_{size}_xeon/
# Default: models (artifacts stored in models/whisper_base_xeon/, models/whisper_small_xeon/, etc.)
# For backward compatibility with existing deployments, you can set this to "." to use project root
WHISPER_ARTIFACTS_DIR=models

# Language for transcription (vi, en, etc.)
WHISPER_LANGUAGE=vi

# Model name (matches WHISPER_MODEL_SIZE typically)
WHISPER_MODEL=small

# Number of CPU threads for Whisper inference
# 0 = auto-detect (uses min(cpu_count, 8) for optimal performance)
# Set explicit value (1-16) to override
WHISPER_N_THREADS=0

# ============================================================================
# Chunking Configuration (for long audio processing)
# ============================================================================
# Enable/disable automatic chunking for long audio files
# When enabled, audio > WHISPER_CHUNK_DURATION will be split and processed sequentially
WHISPER_CHUNK_ENABLED=true

# Duration of each audio chunk in seconds
# Default: 30s (optimal for Whisper model, trained on ~30s segments)
# Increase for faster processing with more memory, decrease for lower memory usage
WHISPER_CHUNK_DURATION=30

# Overlap between consecutive chunks in seconds
# Helps preserve words cut at chunk boundaries
# Default: 1s (covers average word duration of 0.3-0.5s)
WHISPER_CHUNK_OVERLAP=1

# ============================================================================
# MinIO Configuration (for artifact download)
# ============================================================================
# MinIO endpoint for downloading Whisper library artifacts
MINIO_ENDPOINT=http://172.16.19.115:9000

# MinIO credentials
MINIO_ACCESS_KEY=smap
MINIO_SECRET_KEY=hcmut2025

# ============================================================================
# API Security & Timeouts
# ============================================================================
# Internal API key for authentication
INTERNAL_API_KEY=smap-internal-key-changeme

# Base transcription timeout in seconds
# Note: Adaptive timeout is automatically calculated for long audio
# Formula: max(TRANSCRIBE_TIMEOUT_SECONDS, audio_duration * 1.5)
TRANSCRIBE_TIMEOUT_SECONDS=30

# ============================================================================
# Logging Settings
# ============================================================================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log format: console (colored) or json (for log aggregation like ELK, Datadog)
LOG_FORMAT=console

# Enable file logging (logs/app.log and logs/error.log)
LOG_FILE_ENABLED=true

# Log level for standalone scripts (download_whisper_artifacts.py, benchmark.py)
SCRIPT_LOG_LEVEL=INFO


# ============================================================================
# Redis Configuration (for async job state management)
# ============================================================================
# Redis host (use localhost for local dev, redis for docker-compose)
REDIS_HOST=localhost

# Redis port
REDIS_PORT=6379

# Redis password (leave empty if no auth required)
REDIS_PASSWORD=

# Redis database number (0-15)
REDIS_DB=0

# Job state TTL in seconds (default: 1 hour)
# After this time, job state is automatically deleted from Redis
# Crawler should complete polling within this window
REDIS_JOB_TTL=3600
