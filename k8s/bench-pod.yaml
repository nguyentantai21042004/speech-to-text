# =============================================================================
# Whisper Benchmark Pod for K8s Xeon Cluster
# =============================================================================
# This Pod runs the benchmark script on Xeon cluster with CPU isolation.
# Results are used to calculate Normalization Ratio for resource sizing.
#
# Usage:
#   kubectl apply -f k8s/bench-configmap.yaml
#   kubectl apply -f k8s/bench-pod.yaml
#   kubectl logs -f benchmark-xeon
#   kubectl cp benchmark-xeon:/app/scripts/benchmark_results/xeon_result.json ./xeon_result.json
#
# Important:
#   - requests = limits for QoS Guaranteed class
#   - restartPolicy: Never to prevent re-runs
#   - CPU limit = 1 core for fair comparison with Mac M4
# =============================================================================
apiVersion: v1
kind: Pod
metadata:
  name: benchmark-xeon
  namespace: stt
  labels:
    app: stt-benchmark
    purpose: performance-testing
  annotations:
    description: "Whisper benchmark for Normalization Ratio calculation"
spec:
  restartPolicy: Never  # Don't restart after completion
  
  # Security Context
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000
  
  containers:
  - name: benchmark
    image: your-registry/stt-api:latest  # Replace with your registry
    imagePullPolicy: Always
    
    # Benchmark command with configurable parameters
    command:
    - python
    - scripts/benchmark.py
    args:
    - --iterations
    - "$(BENCHMARK_ITERATIONS)"
    - --model-size
    - "$(BENCHMARK_MODEL_SIZE)"
    - --output
    - "$(BENCHMARK_OUTPUT_PATH)"
    
    # Environment variables from ConfigMap
    envFrom:
    - configMapRef:
        name: bench-config
    
    # Additional environment variables
    env:
    - name: WHISPER_MODEL_SIZE
      valueFrom:
        configMapKeyRef:
          name: bench-config
          key: BENCHMARK_MODEL_SIZE
    - name: WHISPER_N_THREADS
      value: "1"  # Single thread for fair comparison
    
    # Resource Limits - QoS Guaranteed (requests = limits)
    # CRITICAL: CPU limit = 1 core for fair comparison with Mac M4
    resources:
      requests:
        cpu: "1"        # Exactly 1 CPU core
        memory: "2Gi"   # 2GB RAM for model loading
      limits:
        cpu: "1"        # Same as requests for QoS Guaranteed
        memory: "2Gi"   # Same as requests for QoS Guaranteed
    
    # Volume mounts
    volumeMounts:
    - name: benchmark-results
      mountPath: /app/scripts/benchmark_results
    - name: whisper-models
      mountPath: /app/whisper_base_xeon
      subPath: whisper_base_xeon
    - name: whisper-models
      mountPath: /app/whisper_small_xeon
      subPath: whisper_small_xeon
    - name: whisper-models
      mountPath: /app/whisper_medium_xeon
      subPath: whisper_medium_xeon
    
    # Security Context
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: false
      capabilities:
        drop:
        - ALL
  
  # Volumes
  volumes:
  - name: benchmark-results
    emptyDir:
      sizeLimit: 100Mi
  - name: whisper-models
    persistentVolumeClaim:
      claimName: stt-models-pvc

---
# =============================================================================
# Benchmark Pod with Stress Test Mode
# =============================================================================
# Use this Pod to run multi-thread stress test for throttling detection.
# =============================================================================
apiVersion: v1
kind: Pod
metadata:
  name: benchmark-xeon-stress
  namespace: stt
  labels:
    app: stt-benchmark
    purpose: stress-testing
  annotations:
    description: "Whisper stress test for CPU throttling detection"
spec:
  restartPolicy: Never
  
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000
  
  containers:
  - name: benchmark-stress
    image: your-registry/stt-api:latest
    imagePullPolicy: Always
    
    # Stress test command
    command:
    - python
    - scripts/benchmark.py
    - --stress
    - --model-size
    - "$(BENCHMARK_MODEL_SIZE)"
    
    envFrom:
    - configMapRef:
        name: bench-config
    
    env:
    - name: WHISPER_MODEL_SIZE
      valueFrom:
        configMapKeyRef:
          name: bench-config
          key: BENCHMARK_MODEL_SIZE
    
    # Same resource limits as regular benchmark
    resources:
      requests:
        cpu: "1"
        memory: "2Gi"
      limits:
        cpu: "1"
        memory: "2Gi"
    
    volumeMounts:
    - name: whisper-models
      mountPath: /app/whisper_base_xeon
      subPath: whisper_base_xeon
    - name: whisper-models
      mountPath: /app/whisper_small_xeon
      subPath: whisper_small_xeon
    - name: whisper-models
      mountPath: /app/whisper_medium_xeon
      subPath: whisper_medium_xeon
    
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: false
      capabilities:
        drop:
        - ALL
  
  volumes:
  - name: whisper-models
    persistentVolumeClaim:
      claimName: stt-models-pvc
